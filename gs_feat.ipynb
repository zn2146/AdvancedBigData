{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'close', 'low', 'volume', 'price_change',\n",
       "       'p_change', 'ma5', 'ma10', 'ma20', 'v_ma5', 'v_ma10', 'v_ma20',\n",
       "       'turnover', 'mom_label', 'moment', 'cv', 'volatility', 'pres1', 'pres2',\n",
       "       'npres1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gongshang = pd.read_csv('price_gongshang.csv')\n",
    "gongshang.columns[:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags=2\n",
    "gongshanglag = pd.DataFrame(index=gongshang.index)\n",
    "gongshanglag[\"close\"] = gongshang[\"close\"]\n",
    "gongshanglag[\"open\"] = gongshang[\"open\"]\n",
    "gongshanglag[\"high\"] = gongshang[\"high\"]\n",
    "gongshanglag[\"low\"] = gongshang[\"low\"]\n",
    "gongshanglag[\"moment\"] = gongshang[\"moment\"]\n",
    "gongshanglag[\"volatility\"] = gongshang[\"volatility\"]\n",
    "gongshanglag[\"npres1\"] = gongshang[\"npres1\"]\n",
    "gongshanglag[\"npres2\"] = gongshang[\"npres2\"]\n",
    "\n",
    "\n",
    "gongshanglag[\"volume\"] = gongshang[\"volume\"]\n",
    "for i in range(0, lags):\n",
    "    gongshanglag[\"Lag%s\" % str(i+1)] = gongshang[\"close\"].shift(i+1)\n",
    "    \n",
    "for i in range(0, 1):\n",
    "    gongshanglag[\"open%s\" % str(i+1)] = gongshang[\"open\"].shift(i+1)\n",
    "    gongshanglag[\"close%s\" % str(i+1)] = gongshang[\"close\"].shift(i+1)\n",
    "    gongshanglag[\"high%s\" % str(i+1)] = gongshang[\"high\"].shift(i+1)\n",
    "    gongshanglag[\"low%s\" % str(i+1)] = gongshang[\"low\"].shift(i+1)\n",
    "    gongshanglag[\"moment%s\" % str(i+1)] = gongshang[\"moment\"].shift(i+1)\n",
    "    gongshanglag[\"volatility%s\" % str(i+1)] = gongshang[\"volatility\"].shift(i+1)\n",
    "    gongshanglag[\"npres1%s\" % str(i+1)] = gongshang[\"npres1\"].shift(i+1)\n",
    "    gongshanglag[\"npres2%s\" % str(i+1)] = gongshang[\"npres2\"].shift(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Create the returns DataFrame\n",
    "gsret = pd.DataFrame(index=gongshanglag.index)\n",
    "gsret[\"volume\"] = gongshanglag[\"volume\"]\n",
    "gsret[\"close\"] = gongshanglag[\"close\"].pct_change()*100.0\n",
    "gsret[\"open\"]=gongshanglag[\"open\"] \n",
    "#gsret[\"close\"]=gongshanglag[\"close\"] \n",
    "\n",
    "gsret[\"high\"]=gongshanglag[\"high\"] \n",
    "gsret[\"low\"]=gongshanglag[\"low\"]\n",
    "gsret[\"moment\"]=gongshanglag[\"moment\"] \n",
    "gsret[\"volatility\"]=gongshanglag[\"volatility\"] \n",
    "gsret[\"npres1\"]=gongshanglag[\"npres1\"] \n",
    "gsret[\"npres2\"]=gongshanglag[\"npres2\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(gsret[\"close\"]):\n",
    "    if (abs(x) < 0.0001):\n",
    "        gsret[\"close\"][i] = 0.0001\n",
    "gsret[\"close\"][0] = gsret[\"close\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, lags):\n",
    "    gsret[\"Lag%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"Lag%s\" % str(i+1)].pct_change()*100.0\n",
    "    \n",
    "for i in range(0, 1):\n",
    "    gsret[\"open%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"open%s\" % str(i+1)]\n",
    "    gsret[\"close%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"close%s\" % str(i+1)]\n",
    "    gsret[\"high%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"high%s\" % str(i+1)]\n",
    "    gsret[\"low%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"low%s\" % str(i+1)]\n",
    "    gsret[\"moment%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"moment%s\" % str(i+1)]\n",
    "    gsret[\"volatility%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"volatility%s\" % str(i+1)]\n",
    "    gsret[\"npres1%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"npres1%s\" % str(i+1)]\n",
    "    gsret[\"npres2%s\" % str(i+1)] = \\\n",
    "    gongshanglag[\"npres2%s\" % str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['close', 'open1', 'close1', 'high1', 'low1', 'moment1', 'volatility1',\n",
       "       'npres11', 'npres21', 'Lag1', 'Lag2', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsret[\"label\"] = np.sign(gsret[\"close\"])\n",
    "gsret['Lag1'][:2] = 0.0001\n",
    "gsret['Lag2'][:3] = 0.0001\n",
    "gsret['open1'][0] = gsret['open'][0]\n",
    "gsret['close1'][0] = gongshanglag['close'][0]\n",
    "\n",
    "gsret['high1'][0] = gsret['high'][0]\n",
    "gsret['low1'][0] = gsret['low'][0]\n",
    "gsret['moment1'][0] = gsret['moment'][0]\n",
    "gsret['volatility1'][0] = gsret['volatility'][0]\n",
    "gsret['npres11'][0] = gsret['npres1'][0]\n",
    "gsret['npres21'][0] = gsret['npres2'][0]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "gsret_scaled = pd.DataFrame(scaler.fit_transform(gsret[['close','open1','close1','high1','low1','moment1', 'volatility1','npres11', 'npres21', 'Lag1','Lag2']]), columns=gsret[['close','open1','close1','high1','low1','moment1', 'volatility1','npres11', 'npres21','Lag1','Lag2']].columns)\n",
    "gsret_scaled[\"label\"] = np.sign(gsret[\"close\"])\n",
    "gsret_scaled.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gsret_scaled[[\"open1\",\"high1\", 'low1','close1']]\n",
    "X1 = gsret_scaled[[\"Lag1\",\"Lag2\"]]\n",
    "X2 = gsret_scaled[[\"open1\",\"high1\", 'low1','close1','volatility1']]\n",
    "X3 = gsret_scaled[['npres11','npres21']]\n",
    "\n",
    "y = gsret_scaled[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_test = int(0.7*len(X.index))\n",
    "# Create training and test sets\n",
    "X_train = X[X.index < start_test]\n",
    "X_test = X[X.index >= start_test]\n",
    "\n",
    "X_train1 = X1[X1.index < start_test]\n",
    "X_test1 = X1[X1.index >= start_test]\n",
    "\n",
    "X_train2 = X2[X2.index < start_test]\n",
    "X_test2 = X2[X2.index >= start_test]\n",
    "\n",
    "X_train3 = X3[X3.index < start_test]\n",
    "X_test3 = X3[X3.index >= start_test]\n",
    "\n",
    "y_train = y[y.index < start_test]\n",
    "y_test = y[y.index >= start_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"LR\", LogisticRegression()), \n",
    "              (\"LSVC\", LinearSVC()),\n",
    "              #(\"RSVM\", SVC(\n",
    "               # C=1000000.0, cache_size=200, class_weight=None,\n",
    "               # coef0=0.0, degree=3, gamma=0.0001, kernel='rbf',\n",
    "               # max_iter=-1, probability=False, random_state=None,\n",
    "               # shrinking=True, tol=0.001, verbose=False)\n",
    "              #),\n",
    "              (\"DT\", tree.DecisionTreeClassifier(max_depth=5)),\n",
    "              (\"RF\", RandomForestClassifier(\n",
    "                n_estimators=100, criterion='gini', \n",
    "                max_depth=4, min_samples_split=3, \n",
    "                min_samples_leaf=1, max_features='auto', \n",
    "                bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                random_state=None, verbose=0)),\n",
    "               (\"GBT\", GradientBoostingClassifier(learning_rate=0.01,\n",
    "                n_estimators=100, subsample=0.9, min_samples_split=3, max_depth=2))\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "0.450\n",
      "LSVC:\n",
      "0.441\n",
      "DT:\n",
      "0.486\n",
      "RF:\n",
      "0.477\n",
      "GBT:\n",
      "0.514\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    # Train each of the models on the training set\n",
    "    m[1].fit(X_train, y_train)\n",
    "    \n",
    "    # Make an array of predictions on the test set\n",
    "    pred = m[1].predict(X_test)\n",
    "    print(\"%s:\\n%0.3f\" % (m[0], m[1].score(X_test, y_test)))\n",
    "    #print(\"%s\\n\" % confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_test = gongshang[gongshang.index >= start_test]\n",
    "money = 1000\n",
    "n = 100\n",
    "share = 0\n",
    "track = []\n",
    "for i in range(1,len(pred)):\n",
    "    price = back_test['close'][start_test+i-1]\n",
    "    track.append(money + share*price)\n",
    "    if track[-1] < 0.5 * 1000:\n",
    "        money = track[-1]\n",
    "        share = 0\n",
    "        continue\n",
    "    ret=np.zeros(len(pred))\n",
    "    ret[0] = 0\n",
    "    ret[i] = back_test['close'][start_test+i] - back_test['close'][start_test+i-1]\n",
    "    if pred[i] == 1:\n",
    "        if money > n * price:\n",
    "            share += n\n",
    "            money -= n *price\n",
    "        \n",
    "    else: \n",
    "        share -= n\n",
    "        money += n * price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "back_test = gongshang[gongshang.index >= start_test]\n",
    "money = 1000\n",
    "n = 100\n",
    "share = 0\n",
    "track1 = []\n",
    "for i in range(1,len(pred)):\n",
    "    price = back_test['close'][start_test+i-1]\n",
    "    track1.append(money + share*price)\n",
    "    if track1[-1] < 0.5 * 1000:\n",
    "        money = track1[-1]\n",
    "        share = 0\n",
    "        continue\n",
    "    ret=np.zeros(len(pred))\n",
    "    ret[0] = 0\n",
    "    ret[i] = back_test['close'][start_test+i] - back_test['close'][start_test+i-1]\n",
    "    if pred1[i] == 1:\n",
    "        if money > n * price:\n",
    "            share += n\n",
    "            money -= n *price\n",
    "        \n",
    "    else: \n",
    "        share -= n\n",
    "        money += n * price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "back_test = gongshang[gongshang.index >= start_test]\n",
    "money = 1000\n",
    "n = 100\n",
    "share = 0\n",
    "track2 = []\n",
    "for i in range(1,len(pred)):\n",
    "    price = back_test['close'][start_test+i-1]\n",
    "    track2.append(money + share*price)\n",
    "    if track2[-1] < 0.5 * 1000:\n",
    "        money = track2[-1]\n",
    "        share = 0\n",
    "        continue\n",
    "    ret=np.zeros(len(pred))\n",
    "    ret[0] = 0\n",
    "    ret[i] = back_test['close'][start_test+i] - back_test['close'][start_test+i-1]\n",
    "    if pred2[i] == 1:\n",
    "        if money > n * price:\n",
    "            share += n\n",
    "            money -= n *price\n",
    "        \n",
    "    else: \n",
    "        share -= n\n",
    "        money += n * price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "back_test = gongshang[gongshang.index >= start_test]\n",
    "money = 1000\n",
    "n = 100\n",
    "share = 0\n",
    "track3 = []\n",
    "for i in range(1,len(pred)):\n",
    "    price = back_test['close'][start_test+i-1]\n",
    "    track3.append(money + share*price)\n",
    "    if track3[-1] < 0.5 * 1000:\n",
    "        money = track3[-1]\n",
    "        share = 0\n",
    "        continue\n",
    "    ret=np.zeros(len(pred))\n",
    "    ret[0] = 0\n",
    "    ret[i] = back_test['close'][start_test+i] - back_test['close'][start_test+i-1]\n",
    "    if pred3[i] == 1:\n",
    "        if money > n * price:\n",
    "            share += n\n",
    "            money -= n *price\n",
    "        \n",
    "    else: \n",
    "        share -= n\n",
    "        money += n * price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_para(track, bechmark):\n",
    "    r= np.exp(np.log(track[-1]/track[0])/(len(track)/252)) - 1\n",
    "    r_b = np.exp(np.log(bechmark[-1]/bechmark[0])/(len(bechmark)/252)) - 1\n",
    "    sharp = []\n",
    "    bench = []\n",
    "    r_f = 0.05\n",
    "    r_f_d = np.exp(np.log(1 + r_f)/252) - 1\n",
    "    \n",
    "    for i in range(1,len(track)):\n",
    "        sharp.append(track[i]/track[i-1]-1 -r_f_d)\n",
    "    sharp = np.sqrt(252) * (np.array(sharp).mean())/(np.array(sharp).std())\n",
    "    max_draw = 0\n",
    "    max_l = 0\n",
    "    min_l = max(track)\n",
    "    for i in range(len(track)):\n",
    "        if track[i] > max_l:\n",
    "            max_l = track[i]\n",
    "        if track[i] < min_l:\n",
    "            min_l = track[i]\n",
    "            max_draw = max(max_draw, (max_l - min_l)/max_l)\n",
    "    return {'Annual Return:':r, \"BenchMark:\": r_b, \"Annual Sharpe Ratio:\":sharp, \"max_drawdown:\":max_draw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Annual Return:': -0.94057852562989752,\n",
       " 'Annual Sharpe Ratio:': -1.560560758954751,\n",
       " 'BenchMark:': 0.42429886718074528,\n",
       " 'max_drawdown:': 0.93180015860428234}"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = back_test['close']\n",
    "price = list(price)\n",
    "get_the_para(track, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Annual Return:': 0.45829508837952893,\n",
       " 'Annual Sharpe Ratio:': 1.7941209187465936,\n",
       " 'BenchMark:': 0.42429886718074528,\n",
       " 'max_drawdown:': 0.015999999999999886}"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = back_test['close']\n",
    "price = list(price)\n",
    "get_the_para(track1, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Annual Return:': -0.61932299819363079,\n",
       " 'Annual Sharpe Ratio:': -1.3028293634473143,\n",
       " 'BenchMark:': 0.42429886718074528,\n",
       " 'max_drawdown:': 0.68786127167630062}"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = back_test['close']\n",
    "price = list(price)\n",
    "get_the_para(track2, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Annual Return:': 0.53349981737823149,\n",
       " 'Annual Sharpe Ratio:': 1.9449207307496319,\n",
       " 'BenchMark:': 0.42429886718074528,\n",
       " 'max_drawdown:': 0.019920318725099376}"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = back_test['close']\n",
    "price = list(price)\n",
    "get_the_para(track3, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_para(track, bechmark):\n",
    "    r= np.exp(np.log(track[-1]/track[0])/(len(track)/252)) - 1\n",
    "    r_b = np.exp(np.log(bechmark[-1]/bechmark[0])/(len(bechmark)/252)) - 1\n",
    "    sharp = ((np.array(track).mean() -1000)/1000 - 0.05)/(np.array(track).std() * np.sqrt(len(track)/252))\n",
    "    max_draw = 0\n",
    "    max_l = 0\n",
    "    min_l = max(track)\n",
    "    for i in range(len(track)):\n",
    "        if track[i] > max_l:\n",
    "            max_l = track[i]\n",
    "        if track[i] < min_l:\n",
    "            min_l = track[i]\n",
    "            max_draw = max(max_draw, (max_l - min_l)/max_l)\n",
    "    return {'Annual Return:':r, \"BenchMark:\": r_b, \"Annual Sharpe Ratio:\":sharp, \"max_drawdown:\":max_draw}\n",
    "\n",
    "#get_the_para(track, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models1 = [(\"LR\", LogisticRegression()), \n",
    "              \n",
    "              (\"SVM\", SVC(\n",
    "                C=1000000.0, cache_size=200, class_weight=None,\n",
    "                coef0=0.0, degree=3, gamma=0.01, kernel='poly',\n",
    "                max_iter=-1, probability=False, random_state=None,\n",
    "                shrinking=True, tol=0.001, verbose=False)\n",
    "              ),\n",
    "              (\"DT\", tree.DecisionTreeClassifier(max_depth=8)),\n",
    "              (\"RF\", RandomForestClassifier(\n",
    "                n_estimators=100, criterion='gini', \n",
    "                max_depth=4, min_samples_split=3, \n",
    "                min_samples_leaf=1, max_features='auto', \n",
    "                bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                random_state=None, verbose=0)),\n",
    "               (\"GBT\", GradientBoostingClassifier(learning_rate=0.01,\n",
    "                n_estimators=100, subsample=0.9, min_samples_split=3, max_depth=4))\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "0.573\n",
      "SVM:\n",
      "0.573\n",
      "DT:\n",
      "0.564\n",
      "RF:\n",
      "0.577\n",
      "GBT:\n",
      "0.582\n"
     ]
    }
   ],
   "source": [
    "for m in models1:\n",
    "    # Train each of the models on the training set\n",
    "    m[1].fit(X_train1, y_train)\n",
    "    \n",
    "    # Make an array of predictions on the test set\n",
    "    pred1 = m[1].predict(X_test1)\n",
    "\n",
    "    # Output the hit-rate and the confusion matrix for each model\n",
    "    print(\"%s:\\n%0.3f\" % (m[0], m[1].score(X_test1, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = [(\"LR\", LogisticRegression()), \n",
    "              \n",
    "              (\"SVM\", SVC(\n",
    "                C=1000000.0, cache_size=200, class_weight=None,\n",
    "                coef0=0.0, degree=3, gamma=0.01, kernel='poly',\n",
    "                max_iter=-1, probability=False, random_state=None,\n",
    "                shrinking=True, tol=0.001, verbose=False)\n",
    "              ),\n",
    "              (\"DT\", tree.DecisionTreeClassifier(max_depth=5)),\n",
    "              (\"RF\", RandomForestClassifier(\n",
    "                n_estimators=100, criterion='gini', \n",
    "                max_depth=2, min_samples_split=3, \n",
    "                min_samples_leaf=1, max_features='auto', \n",
    "                bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                random_state=None, verbose=0)),\n",
    "               (\"GBT\", GradientBoostingClassifier(learning_rate=0.01,\n",
    "                n_estimators=100, subsample=0.7, min_samples_split=3, max_depth=5))\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "0.527\n",
      "SVM:\n",
      "0.564\n",
      "DT:\n",
      "0.514\n",
      "RF:\n",
      "0.523\n",
      "GBT:\n",
      "0.559\n"
     ]
    }
   ],
   "source": [
    "for m in models2:\n",
    "    # Train each of the models on the training set\n",
    "    m[1].fit(X_train2, y_train)\n",
    "    \n",
    "    # Make an array of predictions on the test set\n",
    "    pred2 = m[1].predict(X_test2)\n",
    "\n",
    "    # Output the hit-rate and the confusion matrix for each model\n",
    "    print(\"%s:\\n%0.3f\" % (m[0], m[1].score(X_test2, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361.746361746362"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000 / back_test['close'][513] * back_test['close'][732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models3 = [(\"LR\", LogisticRegression()), \n",
    "              \n",
    "              (\"SVM\", SVC(\n",
    "                C=1000000.0, cache_size=200, class_weight=None,\n",
    "                coef0=0.0, degree=3, gamma=0.01, kernel='poly',\n",
    "                max_iter=-1, probability=False, random_state=None,\n",
    "                shrinking=True, tol=0.001, verbose=False)\n",
    "              ),\n",
    "              (\"DT\", tree.DecisionTreeClassifier(max_depth=3)),\n",
    "              (\"RF\", RandomForestClassifier(\n",
    "                n_estimators=100, criterion='gini', \n",
    "                max_depth=2, min_samples_split=3, \n",
    "                min_samples_leaf=1, max_features='auto', \n",
    "                bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                random_state=None, verbose=0)),\n",
    "               (\"GBT\", GradientBoostingClassifier(learning_rate=0.02,\n",
    "                n_estimators=100, subsample=0.9, min_samples_split=5, max_depth=2))\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "0.595\n",
      "SVM:\n",
      "0.577\n",
      "DT:\n",
      "0.595\n",
      "RF:\n",
      "0.605\n",
      "GBT:\n",
      "0.609\n"
     ]
    }
   ],
   "source": [
    "for m in models3:\n",
    "    # Train each of the models on the training set\n",
    "    m[1].fit(X_train3, y_train)\n",
    "    \n",
    "    # Make an array of predictions on the test set\n",
    "    pred3 = m[1].predict(X_test3)\n",
    "\n",
    "    # Output the hit-rate and the confusion matrix for each model\n",
    "    print(\"%s:\\n%0.3f\" % (m[0], m[1].score(X_test3, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
